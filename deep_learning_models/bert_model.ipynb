{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation of BERT based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla T4\n",
      "Is available\n"
     ]
    }
   ],
   "source": [
    "### Getting GPU type\n",
    "print(torch.cuda.get_device_name(0))\n",
    "if torch.cuda.is_available():\n",
    "    print('Is available')\n",
    "else:\n",
    "    print('is not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading allsides only tensors \n",
    "bias_train = torch.load('allsides/allsides_bias_train.pt')#[:1000]\n",
    "bias_val = torch.load('allsides/allsides_bias_val.pt')#[:1000]\n",
    "bias_test = torch.load('allsides/allsides_bias_test.pt')#[:1000]\n",
    "\n",
    "text_train = torch.load('allsides/allsides_contents_text_train.pt')#[:1000,:]\n",
    "text_val = torch.load('allsides/allsides_contents_text_val.pt')#[:1000,:]\n",
    "text_test = torch.load('allsides/allsides_contents_text_test.pt')#[:1000,:]\n",
    "\n",
    "mask_train = torch.load('allsides/allsides_contents_mask_train.pt')#[:1000,:]\n",
    "mask_val = torch.load('allsides/allsides_contents_mask_val.pt')#[:1000,:]\n",
    "mask_test = torch.load('allsides/allsides_contents_mask_test.pt')#[:1000,:]\n",
    "\n",
    "# allsides duplicates removed train\n",
    "# text_train = torch.load('allsides/allsides_duplicates_removed_contents_text_train.pt')\n",
    "# mask_train = torch.load('allsides/allsides_duplicates_removed_contents_mask_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### removing news aggregators (and tabloids) from tensors \n",
    "allsides_source_train = np.load('allsides/allsides_source_train.npy', allow_pickle=True).flatten()\n",
    "allsides_source_val = np.load('allsides/allsides_source_val.npy', allow_pickle=True).flatten()\n",
    "allsides_source_test = np.load('allsides/allsides_source_test.npy', allow_pickle=True).flatten()\n",
    "\n",
    "# sources to be removed:\n",
    "wrongly_labeled = ['RightWingWatch']\n",
    "news_aggregators = ['Drudge Report', 'Real Clear Politics', 'Yahoo News', 'RightWingWatch'] \n",
    "tabloids = ['New York Daily News', 'Daily Mail', 'New York Post'] \n",
    "unwanted_sources = wrongly_labeled + news_aggregators + tabloids\n",
    "# creating boolean array to mark unwanted sources\n",
    "boolean_array_train = np.full((len(allsides_source_train), ), False)\n",
    "boolean_array_val = np.full((len(allsides_source_val), ), False)\n",
    "boolean_array_test = np.full((len(allsides_source_test), ), False)\n",
    "\n",
    "for source in unwanted_sources:\n",
    "    boolean_array_train += allsides_source_train==source\n",
    "    boolean_array_val += allsides_source_val==source \n",
    "    boolean_array_test += allsides_source_test==source \n",
    "# boolean to remove aggregators\n",
    "inverted_boolean_array_train = np.invert(aggregator_boolean_array_train)\n",
    "inverted_boolean_array_val = np.invert(aggregator_boolean_array_val)\n",
    "inverted_boolean_array_test = np.invert(aggregator_boolean_array_test)\n",
    "\n",
    "# bias\n",
    "bias_train = bias_train[inverted_boolean_array_train]\n",
    "bias_val = bias_val[inverted_boolean_array_val]\n",
    "bias_test = bias_test[inverted_boolean_array_test]\n",
    "\n",
    "# text and masks\n",
    "text_train = text_train[inverted_boolean_array_train]\n",
    "text_val = text_val[inverted_boolean_array_val]\n",
    "text_test = text_test[inverted_boolean_array_test]\n",
    "mask_train = mask_train[inverted_boolean_array_train]\n",
    "mask_val = mask_val[inverted_boolean_array_val]\n",
    "mask_test = mask_test[inverted_boolean_array_test]\n",
    "\n",
    "# sources\n",
    "allsides_source_train = allsides_source_train[inverted_boolean_array_train]\n",
    "allsides_source_val = allsides_source_val[inverted_boolean_array_val]\n",
    "allsides_source_test = allsides_source_test[inverted_boolean_array_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(text_train, mask_train, bias_train)\n",
    "val_set = TensorDataset(text_val, mask_val, bias_val)\n",
    "test_set = TensorDataset(text_test, mask_test, bias_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create Model class\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, droput_prob, bert_model_module, output_attentions=False, pooled_output = True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        self.output_attentions = output_attentions\n",
    "        self.pooled_output = pooled_output\n",
    "\n",
    "        self.bert = bert_model_module\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.linear = nn.Linear(hidden_size,hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.classifier_layer = nn.Linear(hidden_size, num_labels) # The values are initialized from U(−sqrt(k),sqrt(k)), where k=1/in_features\n",
    "\n",
    "    def forward(self, text, mask):\n",
    "        # token_type_ids and position_ids are created automaticly \n",
    "        bert_out = self.bert(input_ids = text, attention_mask = mask)\n",
    "        \n",
    "        if self.pooled_output:\n",
    "            ### Pooled Output\n",
    "            # Choosing only CLS token output and apply linear layer + TanH \n",
    "            pooled_out = bert_out[1]\n",
    "            # Applying dropout\n",
    "            pooled_out = self.dropout(pooled_out)\n",
    "\n",
    "            out = self.classifier_layer(pooled_out)\n",
    "        else:\n",
    "            ### Last Layer average\n",
    "            # summing up over sequence lenght and devide by unmasked sequence length \n",
    "            # resulting in tensor with shape (batch_size,hidden_size)\n",
    "            last_layer = torch.sum(bert_out[0], dim=1)/torch.sum(mask,dim=1).reshape([len(mask),1])\n",
    "            last_layer = self.tanh(self.linear(last_layer))\n",
    "            last_layer = self.dropout(last_layer)\n",
    "            out = self.classifier_layer(last_layer)\n",
    "               \n",
    "        # Saving attention layer outputs if set True\n",
    "        if self.output_attentions:\n",
    "            out = out, bert_out[2]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Function for training of 1 epoch\n",
    "\n",
    "def train_fct(train_set, batch_size, return_mse=False, batch_feedback = 1000, first_check = 100, mixed_precision = False, save_memory_usage = False):\n",
    "    start_time = time.time()\n",
    "    # Setting model to train mode (so dropout is applied)\n",
    "    model.train()\n",
    "    # creating iterable dataset devided into batches and shuffled\n",
    "    data = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    # tracking batches, loss, accuracy\n",
    "    total_batch_count = int(len(train_set)/batch_size)\n",
    "    batch_counter = 0\n",
    "    train_loss = 0\n",
    "    train_correctly_specified = 0\n",
    "    train_predicted_values = []\n",
    "    train_true_values = []\n",
    "    \n",
    "    # Tracking memory usage\n",
    "    if save_memory_usage:\n",
    "        ! nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits -f memory_usage.csv # change csv-file name for memory usage here and at the end if wanted\n",
    "\n",
    "    # looping over batches\n",
    "    for text, mask, label in data:\n",
    "        # sending tensors to GPU\n",
    "        text, mask, label = text.to(device), mask.to(device), label.to(device)\n",
    "        # clearing gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(text, mask)\n",
    "        # calculating loss\n",
    "        loss = loss_fct(logits, label)\n",
    "\n",
    "        predictions = logits.argmax(1)\n",
    "        # backpropagation\n",
    "        if mixed_precision:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        # updating weights\n",
    "        optimizer.step()\n",
    "        # loss and metrices messures\n",
    "        train_loss += loss.item()\n",
    "        train_correctly_specified += (predictions == label).sum().item()\n",
    "        \n",
    "        train_predicted_values.append(predictions)\n",
    "        train_true_values.append(label)\n",
    "        \n",
    "        # adding to batchcounter\n",
    "        batch_counter += 1\n",
    "\n",
    "        if (batch_counter % batch_feedback == 0) or (batch_counter == first_check):\n",
    "            time_so_far = time.time() - start_time\n",
    "            minutes = int(time_so_far // 60)\n",
    "            seconds = int(time_so_far % 60)\n",
    "            average_progress_loss = train_loss/batch_counter\n",
    "            progress_acc = train_correctly_specified/(batch_counter*batch_size)\n",
    "            print('-------------------------------------------')\n",
    "            print(f'{batch_counter:5} of {total_batch_count:5} batches done after {minutes:3} min {seconds:2} sec')\n",
    "            print('-------------------------------------------')\n",
    "            print(f'loss: {average_progress_loss:6.4}   |   acc: {progress_acc:6.4}')\n",
    "            print('-------------------------------------------')\n",
    "            #adding memory value\n",
    "            if save_memory_usage:\n",
    "                ! nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits >> memory_usage.csv\n",
    "            \n",
    "    # loss\n",
    "    average_total_loss = train_loss/(len(train_set)/batch_size)\n",
    "    # accuracy\n",
    "    total_accuracy = train_correctly_specified/len(train_set) \n",
    "    # Predicted and true values\n",
    "    train_predicted_values = torch.cat(train_predicted_values).cpu().numpy()\n",
    "    train_true_values = torch.cat(train_true_values).cpu().numpy()\n",
    "    # Precision\n",
    "    train_precision = precision_score(train_true_values, train_predicted_values, average='macro')\n",
    "    # Recall\n",
    "    train_recall = recall_score(train_true_values, train_predicted_values, average='macro')\n",
    "    # F1 score\n",
    "    train_f1_score = f1_score(train_true_values, train_predicted_values, average='macro')\n",
    "    # Mean Squared Error\n",
    "    if return_mse:\n",
    "        train_mse = mean_squared_error(train_true_values,train_predicted_values)\n",
    "    else: \n",
    "        train_mse = None\n",
    "    \n",
    "    # Loading memory usage to get maxium\n",
    "    if save_memory_usage:\n",
    "        memory_usage = np.loadtxt('memory_usage.csv', dtype='int', delimiter = ',') # csv-file name\n",
    "        max_memory_usage = int(np.max(memory_usage))\n",
    "    else:\n",
    "        max_memory_usage = None\n",
    "    \n",
    "    return average_total_loss, total_accuracy, train_precision, train_recall, train_f1_score, train_mse, max_memory_usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Function for validation after 1 epoch of training\n",
    "\n",
    "def val_fct(val_set, batch_size, return_mse=False, return_predicted_values=False):\n",
    "    print('----------- Start Validation/Testing ----------')\n",
    "    # Setting model to evaluation mode (dropout is not applied)\n",
    "    model.eval()\n",
    "    # creating iterable dataset devided into batches, not shuffeled\n",
    "    data = DataLoader(val_set, batch_size = batch_size)\n",
    "    # setting up loss and accuracy variables\n",
    "    val_loss = 0\n",
    "    #val_correctly_specified = 0\n",
    "    val_predicted_values = []\n",
    "    val_true_values = []\n",
    "    # looping over batches\n",
    "    for text, mask, label in data:\n",
    "        text, mask, label = text.to(device), mask.to(device), label.to(device)\n",
    "        # no gradient calculation during validation\n",
    "        with torch.no_grad():\n",
    "            logits = model(text, mask)\n",
    "            # calculating loss\n",
    "            loss = loss_fct(logits, label)            \n",
    "            predictions = logits.argmax(1)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_predicted_values.append(predictions)\n",
    "            val_true_values.append(label)\n",
    "    \n",
    "    # loss\n",
    "    average_val_loss = val_loss/(len(val_set)/batch_size)\n",
    "    # true and predicted values\n",
    "    val_predicted_values = torch.cat(val_predicted_values).cpu().numpy()\n",
    "    val_true_values = torch.cat(val_true_values).cpu().numpy()\n",
    "    # Accuracy\n",
    "    val_accuracy = (val_predicted_values==val_true_values).sum().item()/len(val_set) \n",
    "    # Precision\n",
    "    val_precision = precision_score(val_true_values, val_predicted_values, average='macro')\n",
    "    # Recall\n",
    "    val_recall = recall_score(val_true_values, val_predicted_values, average='macro')\n",
    "    # F1 score\n",
    "    val_f1_score = f1_score(val_true_values, val_predicted_values, average='macro')\n",
    "    # Mean squared error\n",
    "    if return_mse:\n",
    "        val_mse = mean_squared_error(val_true_values,val_predicted_values)\n",
    "    else:\n",
    "        val_mse = None\n",
    "    \n",
    "    if not return_predicted_values:\n",
    "        val_predicted_values = None\n",
    "\n",
    "    return average_val_loss, val_accuracy, val_precision, val_recall, val_f1_score, val_mse, val_predicted_values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Loading Bert \n",
    "BertModel = transformers.BertModel\n",
    "# BertTokenizer = transformers.BertTokenizer\n",
    "# bert_pretrained_weights = 'bert-base-uncased'\n",
    "\n",
    "### Device to run model on, either GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "### Model inputs\n",
    "hidden_size = 768\n",
    "num_labels = 5 \n",
    "dropout_prob = 0.1\n",
    "cost_sensitive = False\n",
    "\n",
    "### Hyperparameters\n",
    "batch_size = 16 \n",
    "learning_rate = 2e-5\n",
    "### Use of nvidia apex for mixed precession calculations\n",
    "mixed_precision = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "##### Initilize and configure Bert\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased') \n",
    "\n",
    "##### Initilize model (reset in model_training_fct below)\n",
    "model = Model(hidden_size, num_labels, dropout_prob, bert_model, pooled_output=True).to(device)\n",
    "\n",
    "### Optimizer, choosing learning rate (reset in model_training_fct below)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "### Applying mixed precision to speed up model training (reset in model_training_fct below)\n",
    "if mixed_precision:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\") \n",
    "### Loss function\n",
    "if cost_sensitive:\n",
    "    loss_fct = CostSensitiveCELoss(num_labels).to(device)\n",
    "else: \n",
    "    loss_fct = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case name for naming saved weight and score files \n",
    "deviation_case = 'allsides_no_aggregators_no_tabloids_duplicates_removed'\n",
    "\n",
    "### Choosing number of epochs to train\n",
    "num_epochs = 2\n",
    "\n",
    "### Dictionary to save metrices\n",
    "metric_scores = {'epoch': [], 'time': [], \n",
    "                 'train_loss': [], 'train_acc': [], 'train_precision': [], 'train_recall': [], 'train_f1_score': [], 'train_mse': [],\n",
    "                 'val_loss': [], 'val_acc': [], 'val_precision': [], 'val_recall': [], 'val_f1_score': [], 'val_mse': []}\n",
    "\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "    # Training for 1 epoch\n",
    "    train_loss, train_acc, train_precision, train_recall, train_f1_score, train_mse, max_memory_usage = train_fct(train_set, \n",
    "                                                                                                                  batch_size, \n",
    "                                                                                                                  return_mse=True, \n",
    "                                                                                                                  batch_feedback=2000, \n",
    "                                                                                                                  first_check=100,\n",
    "                                                                                                                  mixed_precision = mixed_precision, \n",
    "                                                                                                                  save_memory_usage = True)\n",
    "    # Validation\n",
    "    val_loss, val_acc, val_precision, val_recall, val_f1_score, val_mse, val_predicted_values = val_fct(val_set, \n",
    "                                                                                                        batch_size, \n",
    "                                                                                                        return_mse=True, \n",
    "                                                                                                        return_predicted_values=True)\n",
    "    # Display results\n",
    "    end_time = time.time() - epoch_start_time\n",
    "    minutes = int(end_time // 60)\n",
    "    seconds = int(end_time % 60)\n",
    "    print('+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +' + (' + + + + + + +' if train_mse else ''))\n",
    "    print(f'+ Epoch: {epoch} took {minutes:3} min, {seconds:2} sec                             ')\n",
    "    try:\n",
    "        print(f'+ Maximum memory usage: {max_memory_usage:5} MiB')\n",
    "    except TypeError:\n",
    "        pass\n",
    "    print(f'+ (Training)   Loss: {train_loss:6.4}  |  Acc: {train_acc:6.4}  |  F1: {train_f1_score:6.4}  ' + (f'|  MSE: {train_mse:.4}' if train_mse else ''))\n",
    "    print(f'+ (Validation) Loss: {val_loss:6.4}  |  Acc: {val_acc:6.4}  |  F1: {val_f1_score:6.4}  ' + (f'|  MSE: {val_mse:.4}' if val_mse else ''))\n",
    "    print('+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +' + (' + + + + + + +' if train_mse else ''))    \n",
    "    \n",
    "    # saving metrices\n",
    "    current_epoch_score_metrics = ['epoch', 'time', \n",
    "                                   'train_loss', 'train_acc', 'train_precision', 'train_recall', 'train_f1_score', 'train_mse',\n",
    "                                   'val_loss', 'val_acc', 'val_precision', 'val_recall', 'val_f1_score', 'val_mse']\n",
    "    current_epoch_score_values = [epoch, round(end_time/60,2), \n",
    "                                  train_loss, train_acc, train_precision, train_recall, train_f1_score, train_mse,\n",
    "                                  val_loss, val_acc, val_precision, val_recall, val_f1_score, val_mse]\n",
    "    for metric,value in zip(current_epoch_score_metrics, current_epoch_score_values):\n",
    "        metric_scores[metric].append(value)\n",
    "    \n",
    "    # saving model weights \n",
    "    if mixed_precision:\n",
    "        checkpoint = {'model': model.state_dict(),\n",
    "                      'optimizer': optimizer.state_dict(),\n",
    "                      'amp': amp.state_dict()}\n",
    "\n",
    "        torch.save(checkpoint, f'weights/amp_checkpoint_{deviation_case}_epoch{epoch}.pt')\n",
    "    else:\n",
    "        torch.save(model.state_dict(), f'weights/model_weights_{deviation_case}_epoch{epoch}.pt')\n",
    "\n",
    "    # saving final scores\n",
    "    if epoch==num_epochs:\n",
    "        results = pd.DataFrame(metric_scores)\n",
    "        results.to_csv(f'scores/metric_scores_{deviation_case}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the GitHub Discussion regarding gradient overflow: \"Occasionally seeing a message like “overflow detected, skipping step, reducing loss scale” is normal behavior with dynamic loss scaling, and it usually happens in the first few iterations because Amp begins by trying a high loss scale.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_fct(deviation_case, num_epochs, seed):\n",
    "    '''\n",
    "    Function to train model for a given number of epochs and saving all necessery figures and model weights\n",
    "    '''\n",
    "   \n",
    "    ### Dictionary to save metrices\n",
    "    metric_scores = {'epoch': [], 'time': [], \n",
    "                     'train_loss': [], 'train_acc': [], 'train_precision': [], 'train_recall': [], 'train_f1_score': [], 'train_mse': [],\n",
    "                     'val_loss': [], 'val_acc': [], 'val_precision': [], 'val_recall': [], 'val_f1_score': [], 'val_mse': [],\n",
    "                     'test_loss': [], 'test_acc': [], 'test_precision': [], 'test_recall': [], 'test_f1_score': [], 'test_mse': [], 'memory': []}\n",
    "    \n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        # Training for 1 epoch\n",
    "        train_loss, train_acc, train_precision, train_recall, \\\n",
    "        train_f1_score, train_mse, max_memory_usage = train_fct(train_set, \n",
    "                                                                batch_size, \n",
    "                                                                return_mse=True, \n",
    "                                                                batch_feedback=5000, \n",
    "                                                                first_check=100,\n",
    "                                                                mixed_precision = mixed_precision, \n",
    "                                                                save_memory_usage = True)\n",
    "        # Validation\n",
    "        val_loss, val_acc, val_precision, val_recall, val_f1_score, val_mse, val_predicted_values = val_fct(val_set, \n",
    "                                                                                                            batch_size, \n",
    "                                                                                                            return_mse=True, \n",
    "                                                                                                            return_predicted_values=True)\n",
    "\n",
    "        test_loss, test_acc, test_precision, test_recall, test_f1_score, test_mse, test_predicted_values = val_fct(test_set, \n",
    "                                                                                                            batch_size, \n",
    "                                                                                                            return_mse=True, \n",
    "                                                                                                            return_predicted_values=True)\n",
    "\n",
    "        # Display results\n",
    "        end_time = time.time() - epoch_start_time\n",
    "        minutes = int(end_time // 60)\n",
    "        seconds = int(end_time % 60)\n",
    "        print('+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +' + (' + + + + + + +' if train_mse else ''))\n",
    "        print(f'+ Epoch: {epoch} took {minutes:3} min, {seconds:2} sec                             ')\n",
    "        try:\n",
    "            print(f'+ Maximum memory usage: {max_memory_usage:5} MiB')\n",
    "        except TypeError:\n",
    "            pass\n",
    "        print(f'+ (Training)   Loss: {train_loss:6.4}  |  Acc: {train_acc:6.4}  |  F1: {train_f1_score:6.4}  ' + (f'|  MSE: {train_mse:.4}' if train_mse else ''))\n",
    "        print(f'+ (Validation) Loss: {val_loss:6.4}  |  Acc: {val_acc:6.4}  |  F1: {val_f1_score:6.4}  ' + (f'|  MSE: {val_mse:.4}' if val_mse else ''))\n",
    "        print('+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +' + (' + + + + + + +' if train_mse else ''))    \n",
    "\n",
    "        # saving metrices\n",
    "        current_epoch_score_metrics = ['epoch', 'time', \n",
    "                                       'train_loss', 'train_acc', 'train_precision', 'train_recall', 'train_f1_score', 'train_mse',\n",
    "                                       'val_loss', 'val_acc', 'val_precision', 'val_recall', 'val_f1_score', 'val_mse',\n",
    "                                       'test_loss', 'test_acc', 'test_precision', 'test_recall', 'test_f1_score', 'test_mse', 'memory']\n",
    "        current_epoch_score_values = [epoch, round(end_time/60,2), \n",
    "                                      train_loss, train_acc, train_precision, train_recall, train_f1_score, train_mse,\n",
    "                                      val_loss, val_acc, val_precision, val_recall, val_f1_score, val_mse,\n",
    "                                      test_loss, test_acc, test_precision, test_recall, test_f1_score, test_mse, \n",
    "                                      max_memory_usage]\n",
    "        for metric,value in zip(current_epoch_score_metrics, current_epoch_score_values):\n",
    "            metric_scores[metric].append(value)\n",
    "        \n",
    "        # saving model weights \n",
    "        if mixed_precision:\n",
    "            checkpoint = {'model': model.state_dict(),\n",
    "                          'optimizer': optimizer.state_dict(),\n",
    "                          'amp': amp.state_dict()}\n",
    "\n",
    "            torch.save(checkpoint, f'weights/amp_checkpoint_{deviation_case}_epoch{epoch}.pt')\n",
    "        else:\n",
    "            torch.save(model.state_dict(), f'weights/model_weights_{deviation_case}_epoch{epoch}.pt')\n",
    "\n",
    "        # saving final scores\n",
    "        if epoch==num_epochs:\n",
    "            results = pd.DataFrame(metric_scores)\n",
    "            results.to_csv(f'scores/metric_scores_{deviation_case}.csv', index=False)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerunning model to decrease variance due to randomness \n",
    "num_reruns = 3\n",
    "num_epochs = 3\n",
    "deviation_case_start = 'allsides_full'\n",
    "seed = 20\n",
    "\n",
    "for run in range(1,num_reruns+1):\n",
    "    print(f'+ + + + + + + + + + + + + + + + + + START RUN #{run} + + + + + + + + + + + + + + + + + +')\n",
    "    torch.manual_seed(seed)\n",
    "    ### Reseting model\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    model = Model(hidden_size, num_labels, dropout_prob, bert_model, pooled_output=True).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\") \n",
    "\n",
    "    deviation_case = deviation_case_start + f'_rerun_{run}' \n",
    "    model_training_fct(deviation_case, num_epochs, seed)\n",
    "    seed += 1\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### #RUN ###\n",
    "run = 3  ###\n",
    "############\n",
    "num_epochs = 3\n",
    "deviation_case = f'allsides_full_rerun_{run}'\n",
    "seed = 19 + run #20,21,22\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "model_training_fct(deviation_case, num_epochs, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stopping instance\n",
    "! gcloud compute instances stop t4-instance --zone=europe-west4-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 13 11:31:43 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   48C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "#! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
