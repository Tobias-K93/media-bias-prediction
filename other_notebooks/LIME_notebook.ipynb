{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from apex import amp\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from pprint import pprint\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to media-bias-prediction repository \n",
    "repo_path = os.path.dirname(os.getcwd())\n",
    "os.chdir(os.path.join(repo_path, 'other_notebooks'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(repo_path, 'data_preparation','allsides_data'))\n",
    "\n",
    "bias_test = torch.load('allsides_bias_test.pt')\n",
    "text_test = torch.load('allsides_contents_text_test.pt')\n",
    "mask_test = torch.load('allsides_contents_mask_test.pt')\n",
    "\n",
    "os.chdir(os.path.join(repo_path, 'other_notebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(repo_path, 'data_preparation','allsides_data'))\n",
    "\n",
    "allsides_source_test = np.load('allsides_source_test.npy', allow_pickle=True).flatten()\n",
    "\n",
    "# sources to be removed:\n",
    "wrongly_labeled = ['RightWingWatch']\n",
    "news_aggregators = ['Drudge Report', 'Real Clear Politics', 'Yahoo News', 'RightWingWatch'] \n",
    "tabloids = ['New York Daily News', 'Daily Mail', 'New York Post'] \n",
    "unwanted_sources = wrongly_labeled + news_aggregators + tabloids\n",
    "\n",
    "# creating boolean array to mark unwanted sources\n",
    "boolean_array_test = np.full((len(allsides_source_test), ), False)\n",
    "\n",
    "for source in unwanted_sources:\n",
    "    boolean_array_test += allsides_source_test==source \n",
    "\n",
    "# boolean to remove aggregators\n",
    "inverted_boolean_array_test = np.invert(boolean_array_test)\n",
    "\n",
    "# bias\n",
    "bias_test = bias_test[inverted_boolean_array_test]\n",
    "\n",
    "# text and masks\n",
    "text_test = text_test[inverted_boolean_array_test]\n",
    "mask_test = mask_test[inverted_boolean_array_test]\n",
    "\n",
    "# sources\n",
    "allsides_source_test = allsides_source_test[inverted_boolean_array_test]\n",
    "\n",
    "os.chdir(os.path.join(repo_path, 'other_notebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = TensorDataset(text_test, mask_test, bias_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, droput_prob, bert_model_module, output_attentions=False, pooled_output = True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        self.output_attentions = output_attentions\n",
    "        self.pooled_output = pooled_output\n",
    "\n",
    "        self.bert = bert_model_module\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.linear = nn.Linear(hidden_size,hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.classifier_layer = nn.Linear(hidden_size, num_labels) \n",
    "        \n",
    "    def forward(self, text, mask):\n",
    "        # token_type_ids and position_ids are created automaticly \n",
    "        bert_out = self.bert(input_ids = text, attention_mask = mask)\n",
    "        \n",
    "        if self.pooled_output:\n",
    "            # Choosing only CLS token output and apply linear layer + TanH \n",
    "            pooled_out = bert_out[1]\n",
    "            # Applying dropout\n",
    "            pooled_out = self.dropout(pooled_out)\n",
    "\n",
    "            out = self.classifier_layer(pooled_out)\n",
    "        else:\n",
    "            ### Last Layer average\n",
    "            # summing up over sequence lenght and devide by unmasked sequence length \n",
    "            # resulting in tensor with shape (batch_size,hidden_size)\n",
    "            last_layer = torch.sum(bert_out[0], dim=1)/torch.sum(mask,dim=1).reshape([len(mask),1])\n",
    "            last_layer = self.tanh(self.linear(last_layer))\n",
    "            last_layer = self.dropout(last_layer)\n",
    "            out = self.classifier_layer(last_layer)\n",
    "               \n",
    "        # Saving attention layer outputs if set True\n",
    "        if self.output_attentions:\n",
    "            out = out, bert_out[2]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Loading Bert \n",
    "BertModel = transformers.BertModel\n",
    "\n",
    "### Device to run model on, either GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "### Model inputs\n",
    "hidden_size = 768\n",
    "num_labels = 5 \n",
    "dropout_prob = 0.1\n",
    "cost_sensitive = False\n",
    "\n",
    "### Hyperparameters\n",
    "batch_size = 16 \n",
    "learning_rate = 2e-5\n",
    "### Use of nvidia apex for mixed precession calculations\n",
    "mixed_precision = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Initilize and configure Bert\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased') \n",
    "\n",
    "##### Initilize model \n",
    "model = Model(hidden_size, num_labels, dropout_prob, bert_model, pooled_output=True).to(device)\n",
    "\n",
    "### Optimizer, choosing learning rate \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "### Applying mixed precision \n",
    "if mixed_precision:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\") \n",
    "### Loss function\n",
    "if cost_sensitive:\n",
    "    loss_fct = CostSensitiveCELoss(num_labels).to(device)\n",
    "else: \n",
    "    loss_fct = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(repo_path,'deep_learning_models', 'weights', 'amp_checkpoint_allsides_aggregators_tabloids_duplicates_removed_rerun_1_epoch3.pt'))\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and initilizing tokenizer\n",
    "BertTokenizer = transformers.BertTokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_text = text_test\n",
    "true_labels = ['Left', 'Lean Left', 'Center', 'Lean Right', 'Right']\n",
    "true_values = bias_test.numpy()\n",
    "lime_predict_fct__mask = mask_test\n",
    "num_plots = len(true_labels)\n",
    "predicted_labels = true_labels\n",
    "palette = {'Left': 'blue', 'Lean Left': 'slateblue', 'Center': 'grey', 'Lean Right': 'indianred', 'Right': 'red'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_fct(text_input):\n",
    "    '''\n",
    "    Takes in list of strings, where each string is a whole article\n",
    "    \n",
    "    Returns numpy array containing predicted probabilites of shape (d,k)\n",
    "    where d is the number of article samples given and k is the number of classes (5)\n",
    "    '''\n",
    "    prob_list = []\n",
    "    for sample in text_input:\n",
    "        token_list = sample.split(' ')[:-1]\n",
    "        text = torch.tensor(bert_tokenizer.convert_tokens_to_ids(token_list)).unsqueeze(0)\n",
    "        \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            mask = lime_predict_fct__mask[index].clone().detach().unsqueeze(0)  \n",
    "            text, mask = text.to(device), mask.to(device)\n",
    "            output = model(text, mask)\n",
    "            sample_probabilities = F.softmax(output,1).cpu().numpy()\n",
    "            prob_list.append(sample_probabilities)    \n",
    "\n",
    "    probabilities = np.concatenate(prob_list)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose article index# \n",
    "index = 997 #340 #15    #\n",
    "#########################\n",
    "# copy tensor\n",
    "text_tensor = lime_text[index].clone().detach() \n",
    "# create string to feed into LIME explain_instance\n",
    "text_tokens = bert_tokenizer.convert_ids_to_tokens(text_tensor)\n",
    "text_string = ''.join([token + ' ' for token in text_tokens])\n",
    "# look at article \n",
    "print(f'True Label: {true_labels[int(true_values[index])]}   Source: {allsides_source_test[index]}')\n",
    "print('-----------------------------------------------------------------------------') \n",
    "pprint(text_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create explaination object\n",
    "explainer = LimeTextExplainer(class_names=true_labels)\n",
    "exp = explainer.explain_instance(text_string, prediction_fct, num_features=10, labels=[0,1,2,3,4], num_samples=10000) \n",
    "\n",
    "predected_probs = prediction_fct([text_string])\n",
    "print(f'Predicted class: {predicted_labels[np.argmax(predected_probs)]} ,')\n",
    "print(f'True class: {true_labels[int(true_values[index])]}') \n",
    "print(f'Probabilites in %: {predected_probs[0,0]*100:.4} {predicted_labels[0]}, {predected_probs[0,1]*100:.4} {predicted_labels[1]}, '\n",
    "      f'{predected_probs[0,2]*100:.4} {predicted_labels[2]}, {predected_probs[0,3]*100:.4} {predicted_labels[3]}, {predected_probs[0,4]*100:.4} {predicted_labels[4]} ') \n",
    "\n",
    "# extracting lists with word,probability tuples from lime explaination object\n",
    "word_prob_pairs_left = exp.as_list(label=0)\n",
    "word_prob_pairs_moderate_left = exp.as_list(label=1)\n",
    "word_prob_pairs_center = exp.as_list(label=2) \n",
    "word_prob_pairs_moderate_right = exp.as_list(label=3)\n",
    "word_prob_pairs_right = exp.as_list(label=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presenting outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe for easier readability\n",
    "lime_left_df = pd.DataFrame(word_prob_pairs_left, columns=['words left', 'probabilities left (%)'])\n",
    "lime_left_df['probabilities left (%)'] = np.round(lime_left_df['probabilities left (%)']*100,4)\n",
    "\n",
    "lime_moderate_left_df = pd.DataFrame(word_prob_pairs_moderate_left, columns=['words lean left', 'probabilities lean left (%)'])\n",
    "lime_moderate_left_df['probabilities lean left (%)'] = np.round(lime_moderate_left_df['probabilities lean left (%)']*100,4)\n",
    "\n",
    "lime_center_df = pd.DataFrame(word_prob_pairs_center, columns=['words center', 'probabilities center (%)'])\n",
    "lime_center_df['probabilities center (%)'] = np.round(lime_center_df['probabilities center (%)']*100,4)\n",
    "\n",
    "lime_moderate_right_df = pd.DataFrame(word_prob_pairs_moderate_right, columns=['words lean right', 'probabilities lean right (%)'])\n",
    "lime_moderate_right_df['probabilities lean right (%)'] = np.round(lime_moderate_right_df['probabilities lean right (%)']*100,4)\n",
    "\n",
    "lime_right_df = pd.DataFrame(word_prob_pairs_right, columns=['words right', 'probabilities right (%)'])\n",
    "lime_right_df['probabilities right (%)'] = np.round(lime_right_df['probabilities right (%)']*100,4)\n",
    "\n",
    "lime_df = pd.concat([lime_left_df, lime_moderate_left_df, lime_center_df, lime_moderate_right_df, lime_right_df], axis=1) # [lime_left_df, lime_center_df, lime_right_df] \n",
    "#lime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot LIME results\n",
    "general_font_size = 'medium'\n",
    "plt.rcParams.update({'font.size': 17})\n",
    "lime_df_columns = list(lime_df.columns)\n",
    "\n",
    "fig, axes = plt.subplots(1,num_plots, figsize=[24,5])\n",
    "\n",
    "lime_max = 25  # 15\n",
    "lime_min = -25 #-15\n",
    "\n",
    "for i in range(num_plots):\n",
    "    sns.barplot(list(lime_df.iloc[:,i*2+1]), list(lime_df.iloc[:,i*2]), color=palette[predicted_labels[i]], ax=axes[i])\n",
    "    axes[i].set_xlim([lime_min,lime_max])\n",
    "    axes[i].set_xticks([-20,-10,0,10,20]) # [-15,-10,-5,0,5,10,15] \n",
    "    axes[i].grid(True, axis='x')\n",
    "    axes[i].set_title(true_labels[i])\n",
    "    axes[i].set_xlabel('weights (in %)')\n",
    "\n",
    "axes[0].set_ylabel('most relevant words')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_example_name = 'abc_news_white_supremacist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f'lime_{lime_example_name}_plot.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_lime = exp.as_html(predict_proba=False, text=True, opacity=False)\n",
    "\n",
    "with open(f\"lime_{lime_example_name}.html\", \"w\") as file:\n",
    "    file.write(html_lime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save LIME explanation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "with open(f'lime_html_files/lime_{lime_example_name}_explanation', 'wb') as f:\n",
    "    dill.dump(exp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open(f'lime_html_files/lime_{lime_example_name}explanation', 'rb') as f:\n",
    "    exp = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
