{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from apex import amp\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_val = torch.load('allsides/allsides_bias_val.pt')\n",
    "bias_test = torch.load('allsides/allsides_bias_test.pt')\n",
    "\n",
    "text_val = torch.load('allsides/allsides_contents_text_val.pt')\n",
    "text_test = torch.load('allsides/allsides_contents_text_test.pt')\n",
    "\n",
    "mask_val = torch.load('allsides/allsides_contents_mask_val.pt')\n",
    "mask_test = torch.load('allsides/allsides_contents_mask_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsides_source_val = np.load('allsides/allsides_source_val.npy', allow_pickle=True).flatten()\n",
    "allsides_source_test = np.load('allsides/allsides_source_test.npy', allow_pickle=True).flatten()\n",
    "\n",
    "# sources to be removed:\n",
    "wrongly_labeled = ['RightWingWatch']\n",
    "news_aggregators = ['Drudge Report', 'Real Clear Politics', 'Yahoo News', 'RightWingWatch'] \n",
    "tabloids = ['New York Daily News', 'Daily Mail', 'New York Post'] \n",
    "unwanted_sources = wrongly_labeled + news_aggregators + tabloids\n",
    "# creating boolean array to mark unwanted sources\n",
    "boolean_array_val = np.full((len(allsides_source_val), ), False)\n",
    "boolean_array_test = np.full((len(allsides_source_test), ), False)\n",
    "\n",
    "for source in unwanted_sources:\n",
    "    boolean_array_val += allsides_source_val==source \n",
    "    boolean_array_test += allsides_source_test==source \n",
    "# boolean to remove aggregators\n",
    "inverted_boolean_array_val = np.invert(aggregator_boolean_array_val)\n",
    "inverted_boolean_array_test = np.invert(aggregator_boolean_array_test)\n",
    "\n",
    "# bias\n",
    "bias_val = bias_val[inverted_boolean_array_val]\n",
    "bias_test = bias_test[inverted_boolean_array_test]\n",
    "\n",
    "# text and masks\n",
    "text_val = text_val[inverted_boolean_array_val]\n",
    "text_test = text_test[inverted_boolean_array_test]\n",
    "\n",
    "mask_val = mask_val[inverted_boolean_array_val]\n",
    "mask_test = mask_test[inverted_boolean_array_test]\n",
    "\n",
    "# sources\n",
    "allsides_source_val = allsides_source_val[inverted_boolean_array_val]\n",
    "allsides_source_test = allsides_source_test[inverted_boolean_array_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = TensorDataset(text_val, mask_val, bias_val)\n",
    "test_set = TensorDataset(text_test, mask_test, bias_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create Model class\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, droput_prob, bert_model_module, output_attentions=False, pooled_output = True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        self.output_attentions = output_attentions\n",
    "        self.pooled_output = pooled_output\n",
    "\n",
    "        self.bert = bert_model_module\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.linear = nn.Linear(hidden_size,hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.classifier_layer = nn.Linear(hidden_size, num_labels) # The values are initialized from U(âˆ’sqrt(k),sqrt(k)), where k=1/in_features\n",
    "\n",
    "    def forward(self, text, mask):\n",
    "        # token_type_ids and position_ids are created automaticly \n",
    "        bert_out = self.bert(input_ids = text, attention_mask = mask)\n",
    "        \n",
    "        if self.pooled_output:\n",
    "            ### Pooled Output\n",
    "            # Choosing only CLS token output and apply linear layer + TanH \n",
    "            pooled_out = bert_out[1]\n",
    "            # Applying dropout\n",
    "            pooled_out = self.dropout(pooled_out)\n",
    "\n",
    "            out = self.classifier_layer(pooled_out)\n",
    "        else:\n",
    "            ### Last Layer average\n",
    "            # summing up over sequence lenght and devide by unmasked sequence length \n",
    "            # resulting in tensor with shape (batch_size,hidden_size)\n",
    "            last_layer = torch.sum(bert_out[0], dim=1)/torch.sum(mask,dim=1).reshape([len(mask),1])\n",
    "            last_layer = self.tanh(self.linear(last_layer))\n",
    "            last_layer = self.dropout(last_layer)\n",
    "            out = self.classifier_layer(last_layer)\n",
    "               \n",
    "        # Saving attention layer outputs if set True\n",
    "        if self.output_attentions:\n",
    "            out = out, bert_out[2]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Loading Bert \n",
    "BertModel = transformers.BertModel\n",
    "# BertTokenizer = transformers.BertTokenizer\n",
    "# bert_pretrained_weights = 'bert-base-uncased'\n",
    "\n",
    "### Device to run model on, either GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "### Model inputs\n",
    "hidden_size = 768\n",
    "num_labels = 5 \n",
    "dropout_prob = 0.1\n",
    "cost_sensitive = False\n",
    "\n",
    "### Hyperparameters\n",
    "batch_size = 16 \n",
    "learning_rate = 2e-5\n",
    "### Use of nvidia apex for mixed precession calculations\n",
    "mixed_precision = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Initilize and configure Bert\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased') \n",
    "\n",
    "##### Initilize model (reset in model_training_fct below)\n",
    "model = Model(hidden_size, num_labels, dropout_prob, bert_model, pooled_output=True).to(device)\n",
    "\n",
    "### Optimizer, choosing learning rate (reset in model_training_fct below)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "### Applying mixed precision to speed up model training (reset in model_training_fct below)\n",
    "if mixed_precision:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\") \n",
    "### Loss function\n",
    "if cost_sensitive:\n",
    "    loss_fct = CostSensitiveCELoss(num_labels).to(device)\n",
    "else: \n",
    "    loss_fct = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading weights\n",
    "checkpoint = torch.load('FILE_NAME.pt')\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#amp.load_state_dict(checkpoint['amp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_text = text_val\n",
    "true_labels = ['Left', 'Lean Left', 'Center', 'Lean Right', 'Right']\n",
    "true_values = bias_val.numpy()\n",
    "lime_predict_fct__mask = mask_val\n",
    "num_plots = len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_fct(text_input):\n",
    "    '''\n",
    "    Takes in list of strings, where each string is a whole article\n",
    "    \n",
    "    Returns numpy array containing predicted probabilites of shape (d,k)\n",
    "    where d is the number of article samples given and k is the number of classes (5)\n",
    "    '''\n",
    "    prob_list = []\n",
    "    for sample in text_input:\n",
    "        token_list = sample.split(' ')[:-1]\n",
    "        text = torch.tensor(bert_tokenizer.convert_tokens_to_ids(token_list)).unsqueeze(0)\n",
    "        \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            mask = lime_predict_fct__mask[index].clone().detach().unsqueeze(0)  \n",
    "            text, mask = text.to(device), mask.to(device)\n",
    "            output = model(text, mask)\n",
    "            sample_probabilities = F.softmax(output,1).cpu().numpy()\n",
    "            prob_list.append(sample_probabilities)    \n",
    "\n",
    "    probabilities = np.concatenate(prob_list)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose article index \n",
    "index = 5\n",
    "# copy tensor\n",
    "text_tensor = lime_text[index].clone().detach() \n",
    "# create string to feed into LIME explain_instance\n",
    "text_tokens = bert_tokenizer.convert_ids_to_tokens(text_tensor)\n",
    "text_string = ''.join([token + ' ' for token in text_tokens])\n",
    "# look at article \n",
    "#print('Source: ' + sources_array[index]) \n",
    "print('True Label: ' + true_labels[int(true_values[index])]) \n",
    "pprint(text_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create explaination object\n",
    "explainer = LimeTextExplainer(class_names=true_labels) # ['Left', 'Center', 'Right']\n",
    "exp = explainer.explain_instance(text_string, prediction_fct, num_features=10, labels=[0,1,2,3,4], num_samples=5000) # labels=[0,1,2,3,4], top_labels=5\n",
    "\n",
    "predected_probs = prediction_fct([text_string])\n",
    "print(f'Predicted class: {predicted_labels[np.argmax(predected_probs)]} ,')\n",
    "print(f'True class: {true_labels[int(true_values[index])]}') \n",
    "print(f'Probabilites in %: {predected_probs[0,0]*100:.4} {predicted_labels[0]}, {predected_probs[0,1]*100:.4} {predicted_labels[1]}, '\n",
    "      f'{predected_probs[0,2]*100:.4} {predicted_labels[2]}, {predected_probs[0,3]*100:.4} {predicted_labels[3]}, {predected_probs[0,4]*100:.4} {predicted_labels[4]} ') \n",
    "\n",
    "# extracting lists with word,probability tuples from lime explaination object\n",
    "word_prob_pairs_left = exp.as_list(label=0)\n",
    "word_prob_pairs_moderate_left = exp.as_list(label=1)\n",
    "word_prob_pairs_center = exp.as_list(label=2) # 1\n",
    "word_prob_pairs_moderate_right = exp.as_list(label=3)\n",
    "word_prob_pairs_right = exp.as_list(label=4) # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presenting outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe for easier readability\n",
    "lime_left_df = pd.DataFrame(word_prob_pairs_left, columns=['words left', 'probabilities left (%)'])\n",
    "lime_left_df['probabilities left (%)'] = np.round(lime_left_df['probabilities left (%)']*100,4)\n",
    "\n",
    "# added moderate left\n",
    "lime_moderate_left_df = pd.DataFrame(word_prob_pairs_moderate_left, columns=['words moderate left', 'probabilities moderate left (%)'])\n",
    "lime_moderate_left_df['probabilities moderate left (%)'] = np.round(lime_moderate_left_df['probabilities moderate left (%)']*100,4)\n",
    "\n",
    "lime_center_df = pd.DataFrame(word_prob_pairs_center, columns=['words center', 'probabilities center (%)'])\n",
    "lime_center_df['probabilities center (%)'] = np.round(lime_center_df['probabilities center (%)']*100,4)\n",
    "\n",
    "# # added moderate right\n",
    "lime_moderate_right_df = pd.DataFrame(word_prob_pairs_moderate_right, columns=['words moderate right', 'probabilities moderate right (%)'])\n",
    "lime_moderate_right_df['probabilities moderate right (%)'] = np.round(lime_moderate_right_df['probabilities moderate right (%)']*100,4)\n",
    "\n",
    "lime_right_df = pd.DataFrame(word_prob_pairs_right, columns=['words right', 'probabilities right (%)'])\n",
    "lime_right_df['probabilities right (%)'] = np.round(lime_right_df['probabilities right (%)']*100,4)\n",
    "\n",
    "lime_df = pd.concat([lime_left_df, lime_moderate_left_df, lime_center_df, lime_moderate_right_df, lime_right_df], axis=1) # [lime_left_df, lime_center_df, lime_right_df] \n",
    "lime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot LIME results\n",
    "general_font_size = 'medium'\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "lime_df_columns = list(lime_df.columns)\n",
    "\n",
    "fig, axes = plt.subplots(1,num_plots, figsize=[24,5])\n",
    "# selecting min/max probability values from dataframe\n",
    "lime_max = int(np.ceil(np.max(np.array(lime_df.iloc[:,[i for i in range(len(lime_df_columns)) if i%2==1]]))))\n",
    "lime_min = int(np.floor(np.min(np.array(lime_df.iloc[:,[i for i in range(len(lime_df_columns)) if i%2==1]]))))\n",
    "\n",
    "for i in range(num_plots):\n",
    "    sns.barplot(lime_df_columns[i*2+1], lime_df_columns[i*2], data=lime_df, color=train_palette[predicted_labels[i]], ax=axes[i])\n",
    "    axes[i].set_xlim([lime_min,lime_max])\n",
    "#    axes[i].set_xticks(range(lime_min,lime_max,5))\n",
    "    axes[i].grid(True, axis='x')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_lime = exp.as_html(predict_proba=False, text=True, opacity=False)\n",
    "\n",
    "with open(\"lime_example.html\", \"w\") as file:\n",
    "    file.write(html_lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
