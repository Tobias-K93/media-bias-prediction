{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_squared_error\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading allsides only tensors \n",
    "bias_test = torch.load('allsides/allsides_bias_test.pt')\n",
    "text_test = torch.load('allsides/allsides_contents_text_test.pt')\n",
    "mask_test = torch.load('allsides/allsides_contents_mask_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### removing news aggregators (and tabloids) from tensors \n",
    "allsides_source_test = np.load('allsides/allsides_source_test.npy', allow_pickle=True).flatten()\n",
    "\n",
    "# sources to be removed:\n",
    "wrongly_labeled = ['RightWingWatch']\n",
    "news_aggregators = ['Drudge Report', 'Real Clear Politics', 'Yahoo News', 'RightWingWatch'] \n",
    "tabloids = ['New York Daily News', 'Daily Mail', 'New York Post'] \n",
    "unwanted_sources = wrongly_labeled + news_aggregators + tabloids\n",
    "# creating boolean array to mark unwanted sources\n",
    "boolean_array_test = np.full((len(allsides_source_test), ), False)\n",
    "\n",
    "for source in unwanted_sources:\n",
    "    boolean_array_test += allsides_source_test==source \n",
    "# boolean to remove aggregators\n",
    "inverted_boolean_array_test = np.invert(boolean_array_test)\n",
    "\n",
    "# bias\n",
    "bias_test = bias_test[inverted_boolean_array_test]\n",
    "\n",
    "# text and masks\n",
    "text_test = text_test[inverted_boolean_array_test]\n",
    "mask_test = mask_test[inverted_boolean_array_test]\n",
    "\n",
    "# sources\n",
    "allsides_source_test = allsides_source_test[inverted_boolean_array_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = TensorDataset(text_test, mask_test, bias_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, droput_prob, bert_model_module, output_attentions=False, pooled_output = True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        self.output_attentions = output_attentions\n",
    "        self.pooled_output = pooled_output\n",
    "\n",
    "        self.bert = bert_model_module\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.linear = nn.Linear(hidden_size,hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.classifier_layer = nn.Linear(hidden_size, num_labels) # The values are initialized from U(âˆ’sqrt(k),sqrt(k)), where k=1/in_features\n",
    "\n",
    "    def forward(self, text, mask):\n",
    "        # token_type_ids and position_ids are created automaticly \n",
    "        bert_out = self.bert(input_ids = text, attention_mask = mask)\n",
    "        \n",
    "        if self.pooled_output:\n",
    "            ### Pooled Output\n",
    "            # Choosing only CLS token output and apply linear layer + TanH \n",
    "            pooled_out = bert_out[1]\n",
    "            # Applying dropout\n",
    "            pooled_out = self.dropout(pooled_out)\n",
    "\n",
    "            out = self.classifier_layer(pooled_out)\n",
    "        else:\n",
    "            ### Last Layer average\n",
    "            # summing up over sequence lenght and devide by unmasked sequence length \n",
    "            # resulting in tensor with shape (batch_size,hidden_size)\n",
    "            last_layer = torch.sum(bert_out[0], dim=1)/torch.sum(mask,dim=1).reshape([len(mask),1])\n",
    "            last_layer = self.tanh(self.linear(last_layer))\n",
    "            last_layer = self.dropout(last_layer)\n",
    "            out = self.classifier_layer(last_layer)\n",
    "               \n",
    "        # Saving attention layer outputs if set True\n",
    "        if self.output_attentions:\n",
    "            out = out, bert_out[2]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "##### Loading Bert \n",
    "BertModel = transformers.BertModel\n",
    "\n",
    "### Device to run model on, either GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "### Model inputs\n",
    "hidden_size = 768\n",
    "num_labels = 5 \n",
    "dropout_prob = 0.1\n",
    "\n",
    "mixed_precision = True\n",
    "\n",
    "### Hyperparameters\n",
    "batch_size = 16 \n",
    "learning_rate = 2e-5\n",
    "\n",
    "##### Initilize and configure Bert\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased') \n",
    "\n",
    "##### Initilize model \n",
    "model = Model(hidden_size, num_labels, dropout_prob, bert_model, pooled_output=True).to(device)\n",
    "### Applying mixed precision to speed up model inference \n",
    "if mixed_precision:\n",
    "    model = amp.initialize(model, opt_level=\"O1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_fct():\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = DataLoader(test_set, batch_size=batch_size)\n",
    "    test_loss = 0\n",
    "    test_predicted_values = []\n",
    "\n",
    "    number_of_batches = len(test_set)//batch_size\n",
    "    update = 500\n",
    "    batch_counter = 0\n",
    "\n",
    "    for text, mask, label in data:\n",
    "        text, mask, label = text.to(device), mask.to(device), label.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(text,mask)\n",
    "            test_predicted_values.append(output.argmax(1))\n",
    "\n",
    "        batch_counter += 1\n",
    "        if (batch_counter % update == 0) or (batch_counter == 100):\n",
    "            update_time = time.time() - start_time\n",
    "            minutes = int(update_time // 60)\n",
    "            seconds = round(update_time % 60)\n",
    "            print(f'{batch_counter:5} of {number_of_batches} batches done after {minutes:2} min {seconds:2} sec ')\n",
    "            print('-----------------------------------------------')\n",
    "    \n",
    "    print('all batches done')\n",
    "    print('-----------------------------------------------')\n",
    "    test_predicted_values = torch.cat(test_predicted_values).cpu().numpy()\n",
    "    test_true_values = bias_test.numpy()\n",
    "    \n",
    "    return test_predicted_values, test_true_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on small group with_sources run 1\n",
      "  100 of 1271 batches done after  0 min 25 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min  7 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 19 sec \n",
      "-----------------------------------------------\n",
      "           Daily Kos  Washington Monthly  FiveThirtyEight  \\\n",
      "Acc           0.6477              0.5106           0.8302   \n",
      "Frequency    88.0000             47.0000          53.0000   \n",
      "\n",
      "           The Washington Examiner  FrontPage Magazine   remaining  \n",
      "Acc                         0.5098              0.8261      0.9028  \n",
      "Frequency                  51.0000             92.0000  20005.0000  \n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on small group with_sources run 2\n",
      "  100 of 1271 batches done after  0 min 26 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 13 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 29 sec \n",
      "-----------------------------------------------\n",
      "           Daily Kos  Washington Monthly  FiveThirtyEight  \\\n",
      "Acc            0.625              0.4255           0.7358   \n",
      "Frequency     88.000             47.0000          53.0000   \n",
      "\n",
      "           The Washington Examiner  FrontPage Magazine   remaining  \n",
      "Acc                         0.5098              0.9239      0.9121  \n",
      "Frequency                  51.0000             92.0000  20005.0000  \n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on small group with_sources run 3\n",
      "  100 of 1271 batches done after  0 min 26 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 13 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 28 sec \n",
      "-----------------------------------------------\n",
      "           Daily Kos  Washington Monthly  FiveThirtyEight  \\\n",
      "Acc           0.7159              0.4894           0.6981   \n",
      "Frequency    88.0000             47.0000          53.0000   \n",
      "\n",
      "           The Washington Examiner  FrontPage Magazine  remaining  \n",
      "Acc                         0.5294              0.8152      0.904  \n",
      "Frequency                  51.0000             92.0000  20005.000  \n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on small group without_sources run 1\n",
      "  100 of 1271 batches done after  0 min 26 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 13 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 28 sec \n",
      "-----------------------------------------------\n",
      "           Daily Kos  Washington Monthly  FiveThirtyEight  \\\n",
      "Acc           0.4886              0.0851              0.0   \n",
      "Frequency    88.0000             47.0000             53.0   \n",
      "\n",
      "           The Washington Examiner  FrontPage Magazine   remaining  \n",
      "Acc                         0.2549              0.6087      0.9126  \n",
      "Frequency                  51.0000             92.0000  20005.0000  \n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on small group without_sources run 2\n",
      "  100 of 1271 batches done after  0 min 26 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 13 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 28 sec \n",
      "-----------------------------------------------\n",
      "           Daily Kos  Washington Monthly  FiveThirtyEight  \\\n",
      "Acc           0.4773              0.0851           0.0189   \n",
      "Frequency    88.0000             47.0000          53.0000   \n",
      "\n",
      "           The Washington Examiner  FrontPage Magazine  remaining  \n",
      "Acc                         0.2941               0.163      0.908  \n",
      "Frequency                  51.0000              92.000  20005.000  \n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on small group without_sources run 3\n",
      "  100 of 1271 batches done after  0 min 26 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 14 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 28 sec \n",
      "-----------------------------------------------\n",
      "           Daily Kos  Washington Monthly  FiveThirtyEight  \\\n",
      "Acc           0.3409              0.0638              0.0   \n",
      "Frequency    88.0000             47.0000             53.0   \n",
      "\n",
      "           The Washington Examiner  FrontPage Magazine   remaining  \n",
      "Acc                         0.5294              0.3587      0.9112  \n",
      "Frequency                  51.0000             92.0000  20005.0000  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on large group with_sources run 1\n",
      "  100 of 1271 batches done after  0 min 27 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 14 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 30 sec \n",
      "-----------------------------------------------\n",
      "           Politicus USA  ABC News  Reuters  Fox News  CNS News   remaining\n",
      "Acc               0.9337    0.6644      1.0     0.819    0.7987      0.9034\n",
      "Frequency       392.0000  295.0000    342.0   315.000  313.0000  18679.0000\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on large group with_sources run 2\n",
      "  100 of 1271 batches done after  0 min 27 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 15 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 30 sec \n",
      "-----------------------------------------------\n",
      "           Politicus USA  ABC News   Reuters  Fox News  CNS News   remaining\n",
      "Acc               0.9082    0.9254    0.9971    0.7873    0.8466      0.9095\n",
      "Frequency       392.0000  295.0000  342.0000  315.0000  313.0000  18679.0000\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on large group with_sources run 3\n",
      "  100 of 1271 batches done after  0 min 27 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 15 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 30 sec \n",
      "-----------------------------------------------\n",
      "           Politicus USA  ABC News   Reuters  Fox News  CNS News   remaining\n",
      "Acc               0.9439    0.8881    0.9971    0.7714    0.8115      0.9015\n",
      "Frequency       392.0000  295.0000  342.0000  315.0000  313.0000  18679.0000\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on large group without_sources run 1\n",
      "  100 of 1271 batches done after  0 min 27 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 16 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 33 sec \n",
      "-----------------------------------------------\n",
      "           Politicus USA  ABC News  Reuters  Fox News  CNS News   remaining\n",
      "Acc               0.5561    0.4746      0.0    0.2032    0.2045      0.9168\n",
      "Frequency       392.0000  295.0000    342.0  315.0000  313.0000  18679.0000\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on large group without_sources run 2\n",
      "  100 of 1271 batches done after  0 min 27 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 16 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 32 sec \n",
      "-----------------------------------------------\n",
      "           Politicus USA  ABC News   Reuters  Fox News  CNS News   remaining\n",
      "Acc               0.4872       0.4    0.0029    0.0984    0.4505      0.9148\n",
      "Frequency       392.0000     295.0  342.0000  315.0000  313.0000  18679.0000\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "predicting on large group without_sources run 3\n",
      "  100 of 1271 batches done after  0 min 27 sec \n",
      "-----------------------------------------------\n",
      "  500 of 1271 batches done after  2 min 16 sec \n",
      "-----------------------------------------------\n",
      " 1000 of 1271 batches done after  4 min 33 sec \n",
      "-----------------------------------------------\n",
      "           Politicus USA  ABC News  Reuters  Fox News  CNS News   remaining\n",
      "Acc               0.4668    0.5017      0.0    0.0889    0.1853      0.9133\n",
      "Frequency       392.0000  295.0000    342.0  315.0000  313.0000  18679.0000\n"
     ]
    }
   ],
   "source": [
    "small_group = ['Daily Kos','Washington Monthly', 'FiveThirtyEight',                \n",
    "               'The Washington Examiner', 'FrontPage Magazine']                    \n",
    "large_group = ['Politicus USA', 'ABC News', 'Reuters', 'Fox News', 'CNS News']\n",
    "\n",
    "for group_type in ['small', 'large']:\n",
    "    for model_weights in ['with_sources', 'without_sources']:\n",
    "        for run in range(1,4):\n",
    "            ##### Initilize and configure Bert\n",
    "            bert_model = BertModel.from_pretrained('bert-base-uncased') \n",
    "            ##### Initilize model \n",
    "            model = Model(hidden_size, num_labels, dropout_prob, bert_model, pooled_output=True).to(device)\n",
    "            ### Applying mixed precision to speed up model inference \n",
    "            if mixed_precision:\n",
    "                model = amp.initialize(model, opt_level=\"O1\", verbosity=0)\n",
    "\n",
    "            ### Load model weights\n",
    "            if model_weights=='with_sources':\n",
    "                checkpoint = torch.load(f'weights/amp_checkpoint_allsides_aggregators_tabloids_duplicates_removed_rerun_{run}_epoch3.pt') \n",
    "            else:\n",
    "                checkpoint = torch.load(f'weights/amp_checkpoint_allsides_robustness_check_{group_type}_rerun_{run}_epoch3.pt') \n",
    "\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            \n",
    "            ### make predictions\n",
    "            print('+++++++++++++++++++++++++++++++++++++++++++++++') \n",
    "            print(f' predicting on {group_type} group {model_weights} run {run}')\n",
    "            print('+++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "                   \n",
    "            test_predicted_values, test_true_values = prediction_fct()\n",
    "            \n",
    "            # scores of removed sources\n",
    "            if group_type =='small':\n",
    "                removed_sources = small_group\n",
    "            else:\n",
    "                removed_sources = large_group\n",
    "                \n",
    "            removed_sources_scores = []\n",
    "            for i,source in enumerate(removed_sources):\n",
    "                pred = test_predicted_values[allsides_source_test==source]\n",
    "                true = test_true_values[allsides_source_test==source]\n",
    "\n",
    "                removed_sources_accuracy = (pred==true).sum()/len(pred)\n",
    "\n",
    "                removed_sources_scores.append([removed_sources_accuracy, len(pred)])\n",
    "\n",
    "            # scores of remaining sources\n",
    "            kept_sources_boolean = (allsides_source_test!=removed_sources[0])&(allsides_source_test!=removed_sources[1])&(allsides_source_test!=removed_sources[2])&(allsides_source_test!=removed_sources[3])&(allsides_source_test!=removed_sources[4])\n",
    "\n",
    "            kept_sources_pred = test_predicted_values[kept_sources_boolean]\n",
    "            kept_sources_true = test_true_values[kept_sources_boolean]\n",
    "\n",
    "            kept_sources_accuracy = (kept_sources_pred==kept_sources_true).sum()/len(kept_sources_pred)\n",
    "\n",
    "            removed_sources_scores.append([kept_sources_accuracy, len(kept_sources_pred)])\n",
    "\n",
    "            removed_sources_scores = pd.DataFrame(np.array(removed_sources_scores).transpose() , columns=removed_sources+['remaining'], index=['Acc', 'Frequency' ]).round(4)\n",
    "            print(removed_sources_scores)\n",
    "            removed_sources_scores.to_csv(f'scores/accuracy_scores_{group_type}_{model_weights}_run_{run}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
